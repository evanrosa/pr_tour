# Real-Time Flight & Tourism Analysis (Puerto Rico)

## ğŸ“Œ Project Overview
This project builds an **ETL pipeline** using **Kafka, Flink, Spark, and Airflow** to process real-time and historical flight data for **Puerto Rico (SJU Airport)**. The goal is to:

- **Stream real-time flight data** using Kafka.
- **Process streaming data** with Flink.
- **Analyze historical flight trends** using Spark.
- **Orchestrate workflows** using Airflow.
- **Store results** in PostgreSQL for visualization.

## ğŸ— Tech Stack
- **Apache Kafka** â†’ Stream real-time flight data
- **Apache Flink** â†’ Process live streaming data
- **Apache Spark** â†’ Perform batch analytics on historical data
- **Apache Airflow** â†’ Orchestrate and schedule tasks
- **PostgreSQL** â†’ Store processed data
- **Superset/Streamlit** â†’ Dashboard for insights (optional)

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ dags/                  # Airflow DAGs for scheduling
â”‚   â”œâ”€â”€ flight_etl_dag.py  # Airflow DAG for orchestration
â”‚   â”œâ”€â”€ spark_etl.py       # Spark job for batch processing
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ flights/           # Historical flight data (CSV)
â”‚   â”œâ”€â”€ processed/         # Output of Spark jobs
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ kafka_producer.py  # Fetches real-time flight data
â”‚   â”œâ”€â”€ flink_processor.py # Flink job for streaming analysis
â”œâ”€â”€ docker-compose.yml     # Docker setup for Kafka, Spark, Flink, Airflow
â”œâ”€â”€ README.md              # Project documentation
```

## ğŸš€ How to Run the Project
### 1ï¸âƒ£ Start Kafka, Spark, Flink, and Airflow
```bash
docker compose up -d
```

### 2ï¸âƒ£ Run the Kafka Producer (Real-Time Flight Data Fetcher)
```bash
docker compose run kafka_producer
```

### 3ï¸âƒ£ Run the Flink Streaming Processor
```bash
Inside `docker` - flink run -py /opt/flink/job/flink_processor.py
```

### 4ï¸âƒ£ Run the Spark Batch Processor
```bash
python scripts/spark_etl.py
```

### 5ï¸âƒ£ Start Airflow Scheduler & Webserver
```bash
airflow scheduler & airflow webserver
```

### 6ï¸âƒ£ Check DB Tables
```docker exec -it postgres psql -U evro -d pr_tour_superset
```

### You may need to create a user for airflow
```
docker exec -it airflow airflow db upgrade

docker exec -it airflow airflow users create \
  --username abc \
  --firstname Admin \
  --lastname User \
  --role Admin \
  --email admin@example.com \
  --password xyz
```



## ğŸ“Š Data Sources
- **Real-Time Flights:** [AviationStack API](https://aviationstack.com/)
- **Historical Flight Data:** [FAA TranStats](https://www.transtats.bts.gov/)
- **Weather Data (Optional):** [NOAA/NWS API](https://www.weather.gov/documentation/services-web-api)
- **Puerto Rico Open Data:** [data.pr.gov](https://data.pr.gov/)


## flowchart LR
    ```subgraph Data_Sources[Data Sources]
        A[AviationStack API]
        B[Historical Flight Data (FAA)]
    end

    subgraph Streaming_Layer[Streaming Layer]
        A --> C[Kafka Producer]
        C --> D[Kafka Cluster]
        D --> E[Flink Streaming Job]
    end

    subgraph Batch_Layer[Batch Processing Layer]
        B --> F[Airflow DAG]
        F --> G[Spark ETL Job]
    end

    subgraph Storage[Data Storage]
        E --- H[Postgres Database]
        G --- H
    end

    subgraph Visualization[Visualization]
        H --> I[Superset Dashboard]
    end```


## ğŸ¯ Future Enhancements
- âœ… Add real-time **dashboard** using Streamlit or Superset.
- âœ… Implement **machine learning** for flight delay predictions.
- âœ… Optimize Airflow DAGs for better scheduling.

## ğŸ¤ Contributing
Feel free to fork, modify, and contribute to this project! ğŸš€

## ğŸ“œ License
This project is **open-source** under the MIT License.